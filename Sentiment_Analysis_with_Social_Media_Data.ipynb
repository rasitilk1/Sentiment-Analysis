{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis with Social Media Data",
      "provenance": [],
      "collapsed_sections": [
        "dxyifeC0oRhi",
        "LWna_b10oOrZ"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxyifeC0oRhi",
        "colab_type": "text"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vnKZOBHm3Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8N7YMl7nkVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd 'drive/My Drive/Colab Notebooks'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWna_b10oOrZ",
        "colab_type": "text"
      },
      "source": [
        "# Colab Setup for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60V5iDK_oP63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --recursive https://github.com/Microsoft/LightGBM\n",
        "%cd LightGBM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2rYEhGroXAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir build"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSoAXKSapeG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cmake -DUSE_GPU=1 #avoid ..\n",
        "!make -j$(nproc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCyD9yTXplAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/LightGBM/python-package"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YA5XPajpmHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo python setup.py install — precompile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cY6cc8OQlaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo -H pip install vaderSentiment emoji -U"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7t5XqwjjE6h",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA2Y8hKPP2_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import emoji\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "%matplotlib inline\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from scipy.sparse import hstack, csr_matrix, vstack\n",
        "import pickle as pickle\n",
        "analyzer_emoji = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIro5dr_P8B6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('sentiment_data.csv')\n",
        "data.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "data.sentiment = data.sentiment.map({'positive':0,'negative':1})\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEA55vvSQ279",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_emojis(str):\n",
        "    return [c for c in str if c in emoji.UNICODE_EMOJI]\n",
        "def sentiment_emojis(sentence):\n",
        "    emojis = extract_emojis(sentence)\n",
        "    result = [0,0,0,0]\n",
        "    if len(emojis) == 0:\n",
        "        return result\n",
        "    for icon in emojis:\n",
        "        sen_dict = analyzer_emoji.polarity_scores(icon)\n",
        "        sen = [sen_dict['neg'],sen_dict['neu'],sen_dict['pos'],sen_dict['compound']]\n",
        "        result = [result[i] + sen[i] for i in range(4)]\n",
        "    return [result[i] / len(emojis) for i in range(4)]\n",
        "def sentiment_emojis_row(row):\n",
        "    comment = row['text']\n",
        "    sen_comment = sentiment_emojis(comment)\n",
        "    \n",
        "    row['emoji_neg'] = sen_comment[0]\n",
        "    row['emoji_neu'] = sen_comment[1]\n",
        "    row['emoji_pos'] = sen_comment[2]\n",
        "    row['emoji_compound'] = sen_comment[3]\n",
        "    \n",
        "    return row"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axj-oY_jRDUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = data.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPHHigUeQ7hh",
        "colab_type": "code",
        "outputId": "d6309573-2db1-4d98-ddb8-9dde097b94ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''Maybe nltk porter stemmer or punctuation can be try'''\n",
        "\n",
        "df['text'] = df['text'].astype(str).fillna(' ')\n",
        "# Lower case comment\n",
        "df['text'] = df['text'].str.lower()\n",
        "# Add num words of comment as feature\n",
        "df['num_words'] = df['text'].apply(lambda s: len(s.split()))\n",
        "# Add num words unique of comment as feature\n",
        "df['num_unique_words'] = df['text'].apply(lambda s: len(set(w for w in s.split())))\n",
        "# Add num words unique per num words of comment as feature\n",
        "df['words_vs_unique'] = df['num_unique_words'] / df['num_words'] * 100\n",
        "# Add emojis features\n",
        "print(\"Statistical features end!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistical features end!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tw_FijFRCP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df= train_test_split(df, test_size=0.25, random_state=39, stratify=df.sentiment)\n",
        "y_train = train_df['sentiment'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4hSQ6EURzcI",
        "colab_type": "code",
        "outputId": "bda7ea29-80ab-476a-edcb-0e8abb3f674d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Just keep statistic feature to process by model\n",
        "EXCLUED_COLS = ['text','sentiment','tweet_id', 'user_id', 'user_screen_name', 'user_name', 'created_at', 'static_link','Tag','retweets', 'favorites']\n",
        "static_cols = [c for c in train_df.columns if not c in EXCLUED_COLS]\n",
        "print(static_cols)\n",
        "X_train_static = train_df[static_cols]\n",
        "X_test_static = test_df[static_cols]\n",
        "print(X_train_static.shape, X_test_static.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['num_words', 'num_unique_words', 'words_vs_unique']\n",
            "(3591483, 3) (1197162, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJwy45LxRz-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf = TfidfVectorizer(\n",
        "    min_df = 5, \n",
        "    max_df = 0.8, \n",
        "    max_features=10000,\n",
        "    sublinear_tf=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdRRYU6gR08L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_comments = train_df['text'].values\n",
        "test_comments = test_df['text'].values\n",
        "X_train_tfidf = tfidf.fit_transform(train_comments)\n",
        "X_test_tfidf = tfidf.transform(test_comments)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJHrwZCMR1z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('vectorizer.pk', 'wb') as fin:\n",
        "    pickle.dump(tfidf, fin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EneTa6m7R3DM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_train = hstack([X_train_tfidf, csr_matrix(X_train_static)]).tocsr()\n",
        "#X_test = hstack([X_test_tfidf, csr_matrix(X_test_static)]).tocsr()\n",
        "\n",
        "X_train = hstack([X_train_tfidf]).tocsr()\n",
        "X_test = hstack([X_test_tfidf]).tocsr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3m-roG-R4A7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_split, X_valid, y_train_split, y_valid = train_test_split(X_train_tfidf, y_train, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_RYsGJQR44D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param = {'num_leaves':100, 'num_trees':300, 'objective':'binary', \"max_bin\":255, \"learning_rate\":0.1}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTcZ7Oq8R5w-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = lgb.Dataset(X_train_split, y_train_split)\n",
        "valid_data = lgb.Dataset(X_valid, y_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Pmn-EVR6ud",
        "colab_type": "code",
        "outputId": "823eff69-496c-4a40-aa07-5ff3a4aaace3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "bst = lgb.train(param, train_data, num_boost_round=100, valid_sets=[valid_data])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's binary_logloss: 0.604456\n",
            "[2]\tvalid_0's binary_logloss: 0.570083\n",
            "[3]\tvalid_0's binary_logloss: 0.542205\n",
            "[4]\tvalid_0's binary_logloss: 0.519108\n",
            "[5]\tvalid_0's binary_logloss: 0.499579\n",
            "[6]\tvalid_0's binary_logloss: 0.48308\n",
            "[7]\tvalid_0's binary_logloss: 0.468679\n",
            "[8]\tvalid_0's binary_logloss: 0.456291\n",
            "[9]\tvalid_0's binary_logloss: 0.445421\n",
            "[10]\tvalid_0's binary_logloss: 0.435887\n",
            "[11]\tvalid_0's binary_logloss: 0.42745\n",
            "[12]\tvalid_0's binary_logloss: 0.419877\n",
            "[13]\tvalid_0's binary_logloss: 0.412988\n",
            "[14]\tvalid_0's binary_logloss: 0.406981\n",
            "[15]\tvalid_0's binary_logloss: 0.401456\n",
            "[16]\tvalid_0's binary_logloss: 0.396606\n",
            "[17]\tvalid_0's binary_logloss: 0.392069\n",
            "[18]\tvalid_0's binary_logloss: 0.388168\n",
            "[19]\tvalid_0's binary_logloss: 0.38454\n",
            "[20]\tvalid_0's binary_logloss: 0.381338\n",
            "[21]\tvalid_0's binary_logloss: 0.378339\n",
            "[22]\tvalid_0's binary_logloss: 0.375641\n",
            "[23]\tvalid_0's binary_logloss: 0.373194\n",
            "[24]\tvalid_0's binary_logloss: 0.370939\n",
            "[25]\tvalid_0's binary_logloss: 0.368855\n",
            "[26]\tvalid_0's binary_logloss: 0.366953\n",
            "[27]\tvalid_0's binary_logloss: 0.365203\n",
            "[28]\tvalid_0's binary_logloss: 0.363594\n",
            "[29]\tvalid_0's binary_logloss: 0.362098\n",
            "[30]\tvalid_0's binary_logloss: 0.360746\n",
            "[31]\tvalid_0's binary_logloss: 0.359534\n",
            "[32]\tvalid_0's binary_logloss: 0.358326\n",
            "[33]\tvalid_0's binary_logloss: 0.357263\n",
            "[34]\tvalid_0's binary_logloss: 0.356246\n",
            "[35]\tvalid_0's binary_logloss: 0.355307\n",
            "[36]\tvalid_0's binary_logloss: 0.354468\n",
            "[37]\tvalid_0's binary_logloss: 0.353638\n",
            "[38]\tvalid_0's binary_logloss: 0.352863\n",
            "[39]\tvalid_0's binary_logloss: 0.352138\n",
            "[40]\tvalid_0's binary_logloss: 0.351465\n",
            "[41]\tvalid_0's binary_logloss: 0.350814\n",
            "[42]\tvalid_0's binary_logloss: 0.350203\n",
            "[43]\tvalid_0's binary_logloss: 0.349642\n",
            "[44]\tvalid_0's binary_logloss: 0.349135\n",
            "[45]\tvalid_0's binary_logloss: 0.348618\n",
            "[46]\tvalid_0's binary_logloss: 0.348149\n",
            "[47]\tvalid_0's binary_logloss: 0.347715\n",
            "[48]\tvalid_0's binary_logloss: 0.34729\n",
            "[49]\tvalid_0's binary_logloss: 0.346883\n",
            "[50]\tvalid_0's binary_logloss: 0.346504\n",
            "[51]\tvalid_0's binary_logloss: 0.346117\n",
            "[52]\tvalid_0's binary_logloss: 0.345753\n",
            "[53]\tvalid_0's binary_logloss: 0.345412\n",
            "[54]\tvalid_0's binary_logloss: 0.345073\n",
            "[55]\tvalid_0's binary_logloss: 0.344734\n",
            "[56]\tvalid_0's binary_logloss: 0.344425\n",
            "[57]\tvalid_0's binary_logloss: 0.344144\n",
            "[58]\tvalid_0's binary_logloss: 0.343862\n",
            "[59]\tvalid_0's binary_logloss: 0.343594\n",
            "[60]\tvalid_0's binary_logloss: 0.343345\n",
            "[61]\tvalid_0's binary_logloss: 0.343093\n",
            "[62]\tvalid_0's binary_logloss: 0.342835\n",
            "[63]\tvalid_0's binary_logloss: 0.342597\n",
            "[64]\tvalid_0's binary_logloss: 0.342374\n",
            "[65]\tvalid_0's binary_logloss: 0.342132\n",
            "[66]\tvalid_0's binary_logloss: 0.341869\n",
            "[67]\tvalid_0's binary_logloss: 0.341643\n",
            "[68]\tvalid_0's binary_logloss: 0.341402\n",
            "[69]\tvalid_0's binary_logloss: 0.341171\n",
            "[70]\tvalid_0's binary_logloss: 0.340986\n",
            "[71]\tvalid_0's binary_logloss: 0.340756\n",
            "[72]\tvalid_0's binary_logloss: 0.340556\n",
            "[73]\tvalid_0's binary_logloss: 0.340368\n",
            "[74]\tvalid_0's binary_logloss: 0.340202\n",
            "[75]\tvalid_0's binary_logloss: 0.340049\n",
            "[76]\tvalid_0's binary_logloss: 0.339896\n",
            "[77]\tvalid_0's binary_logloss: 0.339722\n",
            "[78]\tvalid_0's binary_logloss: 0.339557\n",
            "[79]\tvalid_0's binary_logloss: 0.339395\n",
            "[80]\tvalid_0's binary_logloss: 0.339216\n",
            "[81]\tvalid_0's binary_logloss: 0.339083\n",
            "[82]\tvalid_0's binary_logloss: 0.339004\n",
            "[83]\tvalid_0's binary_logloss: 0.33911\n",
            "[84]\tvalid_0's binary_logloss: 0.339344\n",
            "[85]\tvalid_0's binary_logloss: 0.339291\n",
            "[86]\tvalid_0's binary_logloss: 0.339406\n",
            "[87]\tvalid_0's binary_logloss: 0.339408\n",
            "[88]\tvalid_0's binary_logloss: 0.340064\n",
            "[89]\tvalid_0's binary_logloss: 0.339628\n",
            "[90]\tvalid_0's binary_logloss: 0.339852\n",
            "[91]\tvalid_0's binary_logloss: 0.340046\n",
            "[92]\tvalid_0's binary_logloss: 0.3406\n",
            "[93]\tvalid_0's binary_logloss: 0.339449\n",
            "[94]\tvalid_0's binary_logloss: 0.339782\n",
            "[95]\tvalid_0's binary_logloss: 0.340418\n",
            "[96]\tvalid_0's binary_logloss: 0.340358\n",
            "[97]\tvalid_0's binary_logloss: 0.340802\n",
            "[98]\tvalid_0's binary_logloss: 0.340708\n",
            "[99]\tvalid_0's binary_logloss: 0.340749\n",
            "[100]\tvalid_0's binary_logloss: 0.341325\n",
            "[101]\tvalid_0's binary_logloss: 0.342017\n",
            "[102]\tvalid_0's binary_logloss: 0.339897\n",
            "[103]\tvalid_0's binary_logloss: 0.340386\n",
            "[104]\tvalid_0's binary_logloss: 0.340956\n",
            "[105]\tvalid_0's binary_logloss: 0.34046\n",
            "[106]\tvalid_0's binary_logloss: 0.342641\n",
            "[107]\tvalid_0's binary_logloss: 0.34076\n",
            "[108]\tvalid_0's binary_logloss: 0.342126\n",
            "[109]\tvalid_0's binary_logloss: 0.340941\n",
            "[110]\tvalid_0's binary_logloss: 0.3422\n",
            "[111]\tvalid_0's binary_logloss: 0.343052\n",
            "[112]\tvalid_0's binary_logloss: 0.342276\n",
            "[113]\tvalid_0's binary_logloss: 0.344472\n",
            "[114]\tvalid_0's binary_logloss: 0.343961\n",
            "[115]\tvalid_0's binary_logloss: 0.347141\n",
            "[116]\tvalid_0's binary_logloss: 0.344213\n",
            "[117]\tvalid_0's binary_logloss: 0.343151\n",
            "[118]\tvalid_0's binary_logloss: 0.34504\n",
            "[119]\tvalid_0's binary_logloss: 0.342079\n",
            "[120]\tvalid_0's binary_logloss: 0.342053\n",
            "[121]\tvalid_0's binary_logloss: 0.344136\n",
            "[122]\tvalid_0's binary_logloss: 0.342866\n",
            "[123]\tvalid_0's binary_logloss: 0.344079\n",
            "[124]\tvalid_0's binary_logloss: 0.347683\n",
            "[125]\tvalid_0's binary_logloss: 0.344772\n",
            "[126]\tvalid_0's binary_logloss: 0.344098\n",
            "[127]\tvalid_0's binary_logloss: 0.348091\n",
            "[128]\tvalid_0's binary_logloss: 0.342652\n",
            "[129]\tvalid_0's binary_logloss: 0.345138\n",
            "[130]\tvalid_0's binary_logloss: 0.342571\n",
            "[131]\tvalid_0's binary_logloss: 0.344191\n",
            "[132]\tvalid_0's binary_logloss: 0.343436\n",
            "[133]\tvalid_0's binary_logloss: 0.344163\n",
            "[134]\tvalid_0's binary_logloss: 0.340953\n",
            "[135]\tvalid_0's binary_logloss: 0.342695\n",
            "[136]\tvalid_0's binary_logloss: 0.344926\n",
            "[137]\tvalid_0's binary_logloss: 0.344804\n",
            "[138]\tvalid_0's binary_logloss: 0.344729\n",
            "[139]\tvalid_0's binary_logloss: 0.346535\n",
            "[140]\tvalid_0's binary_logloss: 0.344508\n",
            "[141]\tvalid_0's binary_logloss: 0.34267\n",
            "[142]\tvalid_0's binary_logloss: 0.342523\n",
            "[143]\tvalid_0's binary_logloss: 0.341592\n",
            "[144]\tvalid_0's binary_logloss: 0.342608\n",
            "[145]\tvalid_0's binary_logloss: 0.343015\n",
            "[146]\tvalid_0's binary_logloss: 0.344463\n",
            "[147]\tvalid_0's binary_logloss: 0.342793\n",
            "[148]\tvalid_0's binary_logloss: 0.344143\n",
            "[149]\tvalid_0's binary_logloss: 0.353345\n",
            "[150]\tvalid_0's binary_logloss: 0.346414\n",
            "[151]\tvalid_0's binary_logloss: 0.341744\n",
            "[152]\tvalid_0's binary_logloss: 0.347374\n",
            "[153]\tvalid_0's binary_logloss: 0.341993\n",
            "[154]\tvalid_0's binary_logloss: 0.341389\n",
            "[155]\tvalid_0's binary_logloss: 0.342556\n",
            "[156]\tvalid_0's binary_logloss: 0.3428\n",
            "[157]\tvalid_0's binary_logloss: 0.348571\n",
            "[158]\tvalid_0's binary_logloss: 0.343906\n",
            "[159]\tvalid_0's binary_logloss: 0.342467\n",
            "[160]\tvalid_0's binary_logloss: 0.343752\n",
            "[161]\tvalid_0's binary_logloss: 0.342217\n",
            "[162]\tvalid_0's binary_logloss: 0.343416\n",
            "[163]\tvalid_0's binary_logloss: 0.342154\n",
            "[164]\tvalid_0's binary_logloss: 0.342142\n",
            "[165]\tvalid_0's binary_logloss: 0.342285\n",
            "[166]\tvalid_0's binary_logloss: 0.342039\n",
            "[167]\tvalid_0's binary_logloss: 0.342991\n",
            "[168]\tvalid_0's binary_logloss: 0.342192\n",
            "[169]\tvalid_0's binary_logloss: 0.345311\n",
            "[170]\tvalid_0's binary_logloss: 0.348282\n",
            "[171]\tvalid_0's binary_logloss: 0.343741\n",
            "[172]\tvalid_0's binary_logloss: 0.342122\n",
            "[173]\tvalid_0's binary_logloss: 0.343229\n",
            "[174]\tvalid_0's binary_logloss: 0.342917\n",
            "[175]\tvalid_0's binary_logloss: 0.342657\n",
            "[176]\tvalid_0's binary_logloss: 0.343174\n",
            "[177]\tvalid_0's binary_logloss: 0.344125\n",
            "[178]\tvalid_0's binary_logloss: 0.342424\n",
            "[179]\tvalid_0's binary_logloss: 0.342148\n",
            "[180]\tvalid_0's binary_logloss: 0.342694\n",
            "[181]\tvalid_0's binary_logloss: 0.350312\n",
            "[182]\tvalid_0's binary_logloss: 0.345145\n",
            "[183]\tvalid_0's binary_logloss: 0.343371\n",
            "[184]\tvalid_0's binary_logloss: 0.343132\n",
            "[185]\tvalid_0's binary_logloss: 0.342666\n",
            "[186]\tvalid_0's binary_logloss: 0.342251\n",
            "[187]\tvalid_0's binary_logloss: 0.344038\n",
            "[188]\tvalid_0's binary_logloss: 0.342053\n",
            "[189]\tvalid_0's binary_logloss: 0.343502\n",
            "[190]\tvalid_0's binary_logloss: 0.344027\n",
            "[191]\tvalid_0's binary_logloss: 0.34322\n",
            "[192]\tvalid_0's binary_logloss: 0.343445\n",
            "[193]\tvalid_0's binary_logloss: 0.343638\n",
            "[194]\tvalid_0's binary_logloss: 0.34334\n",
            "[195]\tvalid_0's binary_logloss: 0.342774\n",
            "[196]\tvalid_0's binary_logloss: 0.343154\n",
            "[197]\tvalid_0's binary_logloss: 0.343934\n",
            "[198]\tvalid_0's binary_logloss: 0.342761\n",
            "[199]\tvalid_0's binary_logloss: 0.342981\n",
            "[200]\tvalid_0's binary_logloss: 0.342733\n",
            "[201]\tvalid_0's binary_logloss: 0.342483\n",
            "[202]\tvalid_0's binary_logloss: 0.345792\n",
            "[203]\tvalid_0's binary_logloss: 0.343308\n",
            "[204]\tvalid_0's binary_logloss: 0.345272\n",
            "[205]\tvalid_0's binary_logloss: 0.344101\n",
            "[206]\tvalid_0's binary_logloss: 0.344142\n",
            "[207]\tvalid_0's binary_logloss: 0.343848\n",
            "[208]\tvalid_0's binary_logloss: 0.345618\n",
            "[209]\tvalid_0's binary_logloss: 0.344262\n",
            "[210]\tvalid_0's binary_logloss: 0.345495\n",
            "[211]\tvalid_0's binary_logloss: 0.344816\n",
            "[212]\tvalid_0's binary_logloss: 0.344936\n",
            "[213]\tvalid_0's binary_logloss: 0.344009\n",
            "[214]\tvalid_0's binary_logloss: 0.34421\n",
            "[215]\tvalid_0's binary_logloss: 0.345341\n",
            "[216]\tvalid_0's binary_logloss: 0.344138\n",
            "[217]\tvalid_0's binary_logloss: 0.344398\n",
            "[218]\tvalid_0's binary_logloss: 0.349955\n",
            "[219]\tvalid_0's binary_logloss: 0.345671\n",
            "[220]\tvalid_0's binary_logloss: 0.346657\n",
            "[221]\tvalid_0's binary_logloss: 0.34615\n",
            "[222]\tvalid_0's binary_logloss: 0.346826\n",
            "[223]\tvalid_0's binary_logloss: 0.347049\n",
            "[224]\tvalid_0's binary_logloss: 0.345554\n",
            "[225]\tvalid_0's binary_logloss: 0.350099\n",
            "[226]\tvalid_0's binary_logloss: 0.350046\n",
            "[227]\tvalid_0's binary_logloss: 0.347027\n",
            "[228]\tvalid_0's binary_logloss: 0.348286\n",
            "[229]\tvalid_0's binary_logloss: 0.347382\n",
            "[230]\tvalid_0's binary_logloss: 0.3474\n",
            "[231]\tvalid_0's binary_logloss: 0.351304\n",
            "[232]\tvalid_0's binary_logloss: 0.348215\n",
            "[233]\tvalid_0's binary_logloss: 0.347324\n",
            "[234]\tvalid_0's binary_logloss: 0.346741\n",
            "[235]\tvalid_0's binary_logloss: 0.346699\n",
            "[236]\tvalid_0's binary_logloss: 0.346717\n",
            "[237]\tvalid_0's binary_logloss: 0.346866\n",
            "[238]\tvalid_0's binary_logloss: 0.346718\n",
            "[239]\tvalid_0's binary_logloss: 0.349952\n",
            "[240]\tvalid_0's binary_logloss: 0.348295\n",
            "[241]\tvalid_0's binary_logloss: 0.351676\n",
            "[242]\tvalid_0's binary_logloss: 0.349829\n",
            "[243]\tvalid_0's binary_logloss: 0.348367\n",
            "[244]\tvalid_0's binary_logloss: 0.348206\n",
            "[245]\tvalid_0's binary_logloss: 0.34858\n",
            "[246]\tvalid_0's binary_logloss: 0.347556\n",
            "[247]\tvalid_0's binary_logloss: 0.348155\n",
            "[248]\tvalid_0's binary_logloss: 0.350478\n",
            "[249]\tvalid_0's binary_logloss: 0.351044\n",
            "[250]\tvalid_0's binary_logloss: 0.35023\n",
            "[251]\tvalid_0's binary_logloss: 0.348258\n",
            "[252]\tvalid_0's binary_logloss: 0.349961\n",
            "[253]\tvalid_0's binary_logloss: 0.349728\n",
            "[254]\tvalid_0's binary_logloss: 0.348006\n",
            "[255]\tvalid_0's binary_logloss: 0.347883\n",
            "[256]\tvalid_0's binary_logloss: 0.358399\n",
            "[257]\tvalid_0's binary_logloss: 0.351478\n",
            "[258]\tvalid_0's binary_logloss: 0.348473\n",
            "[259]\tvalid_0's binary_logloss: 0.348355\n",
            "[260]\tvalid_0's binary_logloss: 0.347781\n",
            "[261]\tvalid_0's binary_logloss: 0.348266\n",
            "[262]\tvalid_0's binary_logloss: 0.348367\n",
            "[263]\tvalid_0's binary_logloss: 0.347811\n",
            "[264]\tvalid_0's binary_logloss: 0.348951\n",
            "[265]\tvalid_0's binary_logloss: 0.349568\n",
            "[266]\tvalid_0's binary_logloss: 0.350538\n",
            "[267]\tvalid_0's binary_logloss: 0.34801\n",
            "[268]\tvalid_0's binary_logloss: 0.347055\n",
            "[269]\tvalid_0's binary_logloss: 0.346942\n",
            "[270]\tvalid_0's binary_logloss: 0.347201\n",
            "[271]\tvalid_0's binary_logloss: 0.346717\n",
            "[272]\tvalid_0's binary_logloss: 0.347336\n",
            "[273]\tvalid_0's binary_logloss: 0.346678\n",
            "[274]\tvalid_0's binary_logloss: 0.347241\n",
            "[275]\tvalid_0's binary_logloss: 0.346829\n",
            "[276]\tvalid_0's binary_logloss: 0.348105\n",
            "[277]\tvalid_0's binary_logloss: 0.348168\n",
            "[278]\tvalid_0's binary_logloss: 0.347512\n",
            "[279]\tvalid_0's binary_logloss: 0.348948\n",
            "[280]\tvalid_0's binary_logloss: 0.348197\n",
            "[281]\tvalid_0's binary_logloss: 0.347509\n",
            "[282]\tvalid_0's binary_logloss: 0.347914\n",
            "[283]\tvalid_0's binary_logloss: 0.348054\n",
            "[284]\tvalid_0's binary_logloss: 0.347497\n",
            "[285]\tvalid_0's binary_logloss: 0.34723\n",
            "[286]\tvalid_0's binary_logloss: 0.360354\n",
            "[287]\tvalid_0's binary_logloss: 0.350255\n",
            "[288]\tvalid_0's binary_logloss: 0.351098\n",
            "[289]\tvalid_0's binary_logloss: 0.349332\n",
            "[290]\tvalid_0's binary_logloss: 0.350369\n",
            "[291]\tvalid_0's binary_logloss: 0.349609\n",
            "[292]\tvalid_0's binary_logloss: 0.348143\n",
            "[293]\tvalid_0's binary_logloss: 0.351441\n",
            "[294]\tvalid_0's binary_logloss: 0.353281\n",
            "[295]\tvalid_0's binary_logloss: 0.35032\n",
            "[296]\tvalid_0's binary_logloss: 0.34853\n",
            "[297]\tvalid_0's binary_logloss: 0.348722\n",
            "[298]\tvalid_0's binary_logloss: 0.348198\n",
            "[299]\tvalid_0's binary_logloss: 0.347834\n",
            "[300]\tvalid_0's binary_logloss: 0.347689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id8UKJvTYKSY",
        "colab_type": "code",
        "outputId": "b08f1700-337b-4894-df85-85cc7f3983aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"accuracy: {}\".format(accuracy_score(y_valid, 1*(bst.predict(X_valid)>0.5))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.8464787595120689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x2dbrJZceyb",
        "colab_type": "code",
        "outputId": "764886d2-46e5-406f-c175-0430d2ed1ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "new_pred = [\"çok kötüyüm\"]\n",
        "new_pred = tfidf.transform(new_pred)\n",
        "bst.predict(new_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.54027656])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nes29qzRevIP",
        "colab_type": "code",
        "outputId": "69be93ca-e4d3-4552-baaa-e35c9ff9be6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "filename = 'lgbm_model.sav'\n",
        "pickle.dump(bst, open(filename, 'wb'))\n",
        " \n",
        "# some time later...\n",
        " \n",
        "# load the model from disk\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "result = loaded_model.predict(new_pred)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.54027656]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hcAEblx2QR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}